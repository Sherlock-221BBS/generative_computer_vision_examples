{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7815474,"sourceType":"datasetVersion","datasetId":4578415}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch \nfrom torch import nn \nfrom torchvision import transforms \nfrom torch.utils.data import DataLoader \nimport torchvision\nfrom tqdm.autonotebook import tqdm\n\ndevice = (\"mps\"\n         if torch.backends.mps.is_available()\n         else \"cuda\"\n         if torch.cuda.is_available()\n         else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-14T17:17:00.519681Z","iopub.execute_input":"2024-03-14T17:17:00.520444Z","iopub.status.idle":"2024-03-14T17:17:09.411050Z","shell.execute_reply.started":"2024-03-14T17:17:00.520395Z","shell.execute_reply":"2024-03-14T17:17:09.409723Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class LinearScheduler:\n    def __init__(self, beta_start, beta_end, num_train_timesteps):\n        self.beta_start = beta_start \n        self.beta_end = beta_end \n        self.num_train_timesteps = num_train_timesteps\n        self.betas = torch.linspace(beta_start, beta_end, num_train_timesteps)\n        self.alphas = 1. - self.betas\n        self.alphas_cumprod = torch.cumprod(self.alphas, dim = 0)\n        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - self.alphas_cumprod)\n        \n    def add_noise(self, original, noise, t):\n        original_shape = original.shape \n        batch_size = original_shape[0]\n        sqrt_alpha_cumprod = self.sqrt_alphas_cumprod[t].reshape(batch_size)\n        sqrt_one_minus_alpha_cumprod = self.sqrt_one_minus_alphas_cumprod[t].reshape(batch_size)\n        \n        for _ in range(len(original_shape) -1):\n            sqrt_alpha_cumprod = sqrt_alpha_cumprod.unsqueeze(-1)\n            sqrt_one_minus_alpha_cumprod = sqrt_one_minus_alpha_cumprod.unsqueeze(-1)\n            \n        return sqrt_alpha_cumprod * original + sqrt_one_minus_alpha_cumprod * noise\n    \n    \n    def sample_prev_timestep(self, xt, noise_pred, t):\n        x0 = (xt - self.sqrt_one_minus_alphas_cumprod[t] * noise_pred)/self.sqrt_alphas_cumprod[t]\n        x0 = torch.clamp(x0, -1, 1)\n        \n        mean = xt - (self.betas[t] * noise_pred)/self.sqrt_one_minus_alphas_cumprod[t]\n        mean = xt/ self.sqrt_alphas_cumprod[t]\n        \n        if t==0:\n            return mean, x0\n        else:\n            variance = self.betas[t] * (1. - self.alphas_cumprod[t-1])\n            variance = variance / (1. - self.alphas_cumprod[t])\n            sigma = variance ** 0.5 \n            z = torch.randn_like(xt).to(xt.device)\n            return mean + sigma * z, x0\n        \n    \n            ","metadata":{"execution":{"iopub.status.busy":"2024-03-14T17:17:09.413261Z","iopub.execute_input":"2024-03-14T17:17:09.413774Z","iopub.status.idle":"2024-03-14T17:17:09.429466Z","shell.execute_reply.started":"2024-03-14T17:17:09.413742Z","shell.execute_reply":"2024-03-14T17:17:09.427039Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def get_time_embedding(timesteps, t_emb_dim = 512):\n    factor = 10000 ** (torch.arange(start = 0, \n                                    end = t_emb_dim // 2, \n                                    device = timesteps.device))\n    t_emb = timesteps[:, None].repeat(1, t_emb_dim//2)/factor\n    t_emb = torch.cat([torch.sin(t_emb), torch.cos(t_emb)], dim = -1)\n    return t_emb\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-14T17:17:09.431575Z","iopub.execute_input":"2024-03-14T17:17:09.432921Z","iopub.status.idle":"2024-03-14T17:17:09.448136Z","shell.execute_reply.started":"2024-03-14T17:17:09.432881Z","shell.execute_reply":"2024-03-14T17:17:09.445530Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class DownBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, t_emb_dim, num_heads, downsample = True):\n        super().__init__()\n        self.downsample = downsample \n        self.conv_first = nn.Sequential(\n                            nn.GroupNorm(8, in_channels), \n                            nn.SiLU(), \n                            nn.Conv2d(in_channels = in_channels, \n                                     out_channels = out_channels, \n                                     kernel_size =3, \n                                     stride = 1, \n                                     padding = 1))\n        self.t_emb_proj = nn.Sequential(\n                            nn.SiLU(), \n                            nn.Linear(t_emb_dim, out_channels))\n        self.conv_second = nn.Sequential(\n                            nn.GroupNorm(8, out_channels),\n                            nn.SiLU(), \n                            nn.Conv2d(in_channels = out_channels, \n                                     out_channels = out_channels, \n                                     kernel_size = 3, \n                                     stride = 1, \n                                     padding = 1))\n        self.attn_norm = nn.GroupNorm(8, out_channels)\n        self.attn = nn.MultiheadAttention(out_channels, num_heads)\n        self.downsample = nn.Conv2d(in_channels = out_channels, \n                                   out_channels = out_channels, \n                                   kernel_size = 3, \n                                   padding = 1, \n                                   stride = 2) if downsample else nn.Identity()\n        \n        self.residual_input_conv = nn.Conv2d(in_channels = in_channels, \n                                            out_channels = out_channels, \n                                            kernel_size = 1)\n        \n    def forward(self, x, t_emb):\n        out = x \n        resnet_input = out \n        \n        out = self.conv_first(out)\n        t_emb = self.t_emb_proj(t_emb)\n        out = out + t_emb[:, :, None, None]\n        out = self.conv_second(out)\n        out= out + self.residual_input_conv(resnet_input)\n        \n        batch_size, channels, h, w = out.shape\n        in_attn = out.reshape(batch_size, channels, h * w)\n        in_attn = self.attn_norm(in_attn)\n        in_attn = in_attn.transpose(1, 2)\n        out_attn, _ = self.attn(in_attn, in_attn, in_attn)\n        out_attn = out_attn.reshape(batch_size, channels, h, w)\n        out = out + out_attn\n        \n        \n        out = self.downsample(out)\n        return out \n    \n        ","metadata":{"execution":{"iopub.status.busy":"2024-03-14T17:17:09.449995Z","iopub.execute_input":"2024-03-14T17:17:09.450385Z","iopub.status.idle":"2024-03-14T17:17:09.471680Z","shell.execute_reply.started":"2024-03-14T17:17:09.450355Z","shell.execute_reply":"2024-03-14T17:17:09.470141Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":" class MidBlock(nn.Module):\n        def __init__(self, in_channels, out_channels, num_heads, t_emb_dim):\n            super().__init__()\n            self.resnet_conv_first = nn.ModuleList([\n                nn.Sequential(nn.GroupNorm(8, in_channels), \n                             nn.SiLU(), \n                             nn.Conv2d(in_channels, out_channels, \n                                      kernel_size = 3, stride = 1, \n                                      padding = 1)), \n                nn.Sequential(nn.GroupNorm(8, out_channels), \n                             nn.SiLU(), \n                             nn.Conv2d(out_channels, out_channels, \n                                      kernel_size = 3, \n                                      stride = 1, padding = 1))\n            ])\n            \n            self.time_projection = nn.ModuleList([\n                nn.Sequential(nn.SiLU(), \n                             nn.Linear(t_emb_dim, out_channels)), \n                nn.Sequential(nn.SiLU(), \n                             nn.Linear(t_emb_dim, out_channels))\n            ])\n            \n            self.attn_norm = nn.GroupNorm(8, out_channels)\n            self.attn = nn.MultiheadAttention(out_channels, num_heads)\n            self.residual_input_conv = nn.ModuleList([\n                nn.Conv2d(in_channels, out_channels, kernel_size = 1), \n                nn.Conv2d(out_channels, out_channels, kernel_size = 1)\n            ])\n            \n            self.resnet_conv_second = nn.ModuleList([\n                nn.Sequential(nn.GroupNorm(8, out_channels), \n                             nn.SiLU(), \n                             nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n                                      stride =1, padding = 1)), \n                nn.Sequential(nn.GroupNorm(8, out_channels), \n                             nn.SiLU(), \n                             nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n                                      stride = 1, padding = 1))\n            ])\n            \n        def forward(self, x, t_emb):\n            out = x \n            residual_input = x\n            \n            out = self.resnet_conv_first[0](x)\n            out = out + self.time_projection[0](t_emb)[:, :, None, None]\n            out = self.resnet_conv_second[0](out)\n            out = out + self.residual_input_conv[0](residual_input)\n            \n            batch_size, channels, h, w = out.shape\n            attn_in = out.reshape(batch_size, channels, h * w)\n            attn_in = self.attn_norm(attn_in)\n            attn_in  = attn_in.transpose(1, 2)\n            out_attn, _ = self.attn(attn_in, attn_in, attn_in)\n            out_attn = out_attn.transpose(1, 2).reshape(batch_size, channels, h, w)\n            out = out + out_attn\n            \n            residual_input = out \n            out = self.resnet_conv_first[1](out)\n            out = out + self.time_projection[1](t_emb)[:, :, None, None]\n            out = self.resnet_conv_second[1](out)\n            out = out + self.residual_input_conv[1](residual_input)\n            \n            return out \n            ","metadata":{"execution":{"iopub.status.busy":"2024-03-14T17:17:09.475524Z","iopub.execute_input":"2024-03-14T17:17:09.476072Z","iopub.status.idle":"2024-03-14T17:17:09.493439Z","shell.execute_reply.started":"2024-03-14T17:17:09.476037Z","shell.execute_reply":"2024-03-14T17:17:09.491306Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class UpBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, num_heads, t_emb_dim, upsample = True):\n        super().__init__()\n        \n        self.resnet_conv_first = nn.Sequential(nn.GroupNorm(8, in_channels), \n                                              nn.SiLU(), \n                                              nn.Conv2d(in_channels, out_channels,\n                                                       kernel_size =3, stride = 1, \n                                                       padding = 1))\n        self.time_projection = nn.Sequential(nn.SiLU(), \n                                            nn.Linear(t_emb_dim, out_channels))\n        self.resnet_conv_second = nn.Sequential(nn.GroupNorm(8, out_channels), \n                                               nn.SiLU(), \n                                               nn.Conv2d(out_channels, out_channels, \n                                                        kernel_size =3, stride = 1, \n                                                        padding = 1))\n        self.attn_norm = nn.GroupNorm(8, out_channels)\n        self.attn = nn.MultiheadAttention(out_channels, num_heads)\n        self.residual_input_conv = nn.Conv2d(in_channels, out_channels, \n                                            kernel_size = 1)\n        self.upsample = nn.ConvTranspose2d(in_channels, \n                                          in_channels, \n                                          kernel_size = 4, \n                                          stride = 2, \n                                          padding = 1) if upsample else nn.Identity()\n        \n    def forward(self, x, out_down, t_emb):\n        \n        out = torch.cat([x, out_down], dim = 1)\n        out = self.upsample(out)\n        \n        residual_input = out\n        out = self.resnet_conv_first(out)\n        out = out + self.time_projection(t_emb)[:, :, None, None]\n        out = self.resnet_conv_second(out)\n        out = out + self.residual_input_conv(residual_input)\n        \n        batch_size, channels, h, w = out.shape\n        attn_in = self.attn_norm(out).reshape(batch_size, channels, h * w)\n        attn_in = attn_in.transpose(1, 2)\n        attn_out, _ = self.attn(attn_in, attn_in, attn_in)\n        attn_out = attn_out.transpose(1, 2).reshape(batch_size, channels, h, w)\n        out =attn_out + out \n\n        \n        return out\n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-14T17:17:09.495448Z","iopub.execute_input":"2024-03-14T17:17:09.496030Z","iopub.status.idle":"2024-03-14T17:17:09.518011Z","shell.execute_reply.started":"2024-03-14T17:17:09.495984Z","shell.execute_reply":"2024-03-14T17:17:09.516860Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, im_channels = 3):\n        super().__init__()\n        self.down_channels = [32, 64, 128, 256]\n        self.mid_channels = [256, 256, 256]\n        self.conv_in = nn.Conv2d(in_channels = im_channels, \n                                out_channels = self.down_channels[0], kernel_size = 3, \n                                stride = 1, padding = 1)\n        self.t_emb_dim = 128\n        self.t_proj = nn.Sequential(\n                    nn.Linear(self.t_emb_dim, self.t_emb_dim), \n                    nn.SiLU(), \n                    nn.Linear(self.t_emb_dim, self.t_emb_dim))\n        self.downblocks = nn.ModuleList()\n        for i in range(len(self.down_channels) - 1):\n            self.downblocks.append(DownBlock(self.down_channels[i], self.down_channels[i+1], \n                                            t_emb_dim = self.t_emb_dim, num_heads = 4, \n                                            downsample = True))\n        self.midblocks = nn.ModuleList()\n        for i in range(len(self.mid_channels) - 1):\n            self.midblocks.append(MidBlock(in_channels = self.mid_channels[i], \n                                          out_channels = self.mid_channels[i+1], \n                                          num_heads = 4, \n                                          t_emb_dim = self.t_emb_dim))\n            \n        self.upblocks = nn.ModuleList()\n        for i in reversed(range(len(self.down_channels))):\n            if i==0:\n                break\n            self.upblocks.append(UpBlock(in_channels = self.down_channels[i] * 2, \n                                        out_channels = self.down_channels[i - 1], \n                                        num_heads = 4, \n                                        t_emb_dim = self.t_emb_dim, \n                                        upsample = True))\n        self.norm_out = nn.GroupNorm(8, self.down_channels[0])\n        self.conv_out = nn.Conv2d(in_channels = self.down_channels[0], \n                                 out_channels = im_channels, \n                                 kernel_size = 1)\n        \n    def forward(self, x, t):\n        out = self.conv_in(x)\n        t_emb = get_time_embedding(t, t_emb_dim = self.t_emb_dim)\n        t_emb = self.t_proj(t_emb)\n        \n        down_outs = []\n        for downblock in self.downblocks:\n            out = downblock(out, t_emb = t_emb)\n#             print(out.shape)\n            down_outs.append(out)\n        \n        for midblock in self.midblocks:\n            out = midblock(out, t_emb = t_emb)\n#             print(out.shape)\n            \n        for upblock in self.upblocks:\n            d_out = down_outs.pop()\n            out = upblock(out, out_down = d_out, t_emb = t_emb)\n#             print(out.shape)\n            \n        out = self.norm_out(out)\n        out = nn.SiLU()(out)\n        out = self.conv_out(out)\n        return out\n        ","metadata":{"execution":{"iopub.status.busy":"2024-03-14T17:17:09.519143Z","iopub.execute_input":"2024-03-14T17:17:09.520403Z","iopub.status.idle":"2024-03-14T17:17:09.541264Z","shell.execute_reply.started":"2024-03-14T17:17:09.520151Z","shell.execute_reply":"2024-03-14T17:17:09.539668Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\n\nBETA_START = 0.0001\nBETA_END = 0.02\nNUM_TRAIN_TIMESTEPS = 1000\nTIME_EMB_DIM= 128\nNUM_EPOCHS = 5\n\nimage_size = 32\nbatch_size = 32\n\n\nscheduler = LinearScheduler(beta_start = BETA_START, \n                           beta_end = BETA_END, \n                           num_train_timesteps = NUM_TRAIN_TIMESTEPS)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-14T17:17:09.543260Z","iopub.execute_input":"2024-03-14T17:17:09.543627Z","iopub.status.idle":"2024-03-14T17:17:09.638607Z","shell.execute_reply.started":"2024-03-14T17:17:09.543596Z","shell.execute_reply":"2024-03-14T17:17:09.637287Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import os\nfrom skimage.io import imread\nfrom tqdm.autonotebook import tqdm\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import transforms\nfrom PIL import Image\n\nlow_res_4x_train_base_path = \"/kaggle/input/div2k-dataset-for-super-resolution/Dataset/DIV2K_train_LR_bicubic_X4/X4/\"\n\nlow_res_4x_train_image_files = sorted(os.listdir(low_res_4x_train_base_path))\n\n\nlow_res_size = 112\n\n\n\nlowres_transform = transforms.Compose(\n    [\n        transforms.Resize((low_res_size, low_res_size), interpolation = Image.NEAREST),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n        \n    ]\n)\n\n\ndef preprocess(image_filename, base_path):\n    image_file_path = os.path.join(base_path, image_filename)\n    im = Image.open(image_file_path)\n    \n    # Resize the image to a common shape, for example, (256, 256)\n    im = lowres_transform(im)\n    return im\n\n# Create separate lists for high-res and low-res images\n\nlow_res_4x_images = [preprocess(image_file, low_res_4x_train_base_path) \n                     for image_file in tqdm(low_res_4x_train_image_files, total=len(low_res_4x_train_image_files))]\n\n# Using TensorDataset with separate tensors\ntrain_dataset = TensorDataset(torch.stack(low_res_4x_images))\n\nbatch_size = 32\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-14T17:17:09.640057Z","iopub.execute_input":"2024-03-14T17:17:09.640528Z","iopub.status.idle":"2024-03-14T17:17:24.840014Z","shell.execute_reply.started":"2024-03-14T17:17:09.640494Z","shell.execute_reply":"2024-03-14T17:17:24.838694Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/800 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f6c03a6811b4b77bd7df93c63cb74dc"}},"metadata":{}}]},{"cell_type":"code","source":"NUM_EPOCHS = 10\ncriterion = nn.MSELoss()\n\n\nunet = UNet(im_channels = 3).to(device)\noptimizer = torch.optim.Adam(unet.parameters(), lr = 1e-3)\n\nlosses = []\n\nfor epoch in tqdm(range(NUM_EPOCHS)):\n    for idx, (batch) in tqdm(enumerate(train_dataloader), total = len(train_dataloader)):\n        optimizer.zero_grad()\n        batch = batch[0].to(device)\n        t = torch.randint(0, 1000, (batch_size, ))\n        noise = torch.randn_like(batch).to(device)\n        noised_images = scheduler.add_noise(batch, noise, t).to(device)\n        noise_pred = unet(noised_images, t)\n        loss = criterion(noise_pred, noise)\n        losses.append(loss.item())\n        loss.backward()\n        optimizer.step()\n        ","metadata":{"execution":{"iopub.status.busy":"2024-03-14T17:23:55.683406Z","iopub.execute_input":"2024-03-14T17:23:55.684218Z","iopub.status.idle":"2024-03-14T17:23:55.691835Z","shell.execute_reply.started":"2024-03-14T17:23:55.684156Z","shell.execute_reply":"2024-03-14T17:23:55.690911Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[nan, nan, nan]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}